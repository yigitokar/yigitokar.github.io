---
title: 'Delta Trick and Taking Derivatives of Inner Products(or other scalars) with respect to vectors and matrices'
date: 2020-04-2
permalink: /posts/2020/delta/
tags:
  - The Delta Trick 
---

In this post I am going to go over a trick called the Delta trick and provide some key results to take derivatives of inner products faster. 

It is a very simple yet powerful tool to take derivatives of scalars with respect to matrices and vectors(and many other things like trace arguments). I should mention "the Delta Trick is your friend. ".  I can say this post is going to be a convex combination of the logic of the derivations and ready-to-use concepts.

Firstly, to be able to use the Delta Trick(and in the end to take the derivatives) we need to express basic Linear algebra terms in terms of summation over indices:

---

- $$c^{T}x = \sum_{j} c_j x_j $$ 
- $$(Bx)_{k} =\sum_{j}b_{kj}x_j $$ 
- $$x^TBx = \sum_{i}\sum_{j}b_{ij}x_ix_j$$
- $$ (AB)_{ij} = \sum_{k}a_{ik}b_{kj}$$ 

---

The derivations of these statements can be easily seen by writing down little toy examples of each case, hence I omit them here. ( Just a little hint on the derivation of $x^TBx$; use the second statement: $ (Bx)_{k} = \sum_{j} b_{kj}x_j $  to make it easier.) 

I also want to emphasize  that if the LHS(or the statement that we want to convert) is a scalar then we just write down the summation-over-index form else if the LHS is a vector or a matrix then we write an arbitrary element ($k^{th}$ element here) in the summation-over-index form.

### So what is the Delta Trick ?

Delta is an operator denoted as $\delta_{ij}$ and is equal to 1 if $i==j$ and equals to 0 otherwise.

When we want to take the derivative of some inner product this tool will come handy. It is easier to see what I mean through an example. 

---

**Example 1**

$\dfrac{\partial c^T x}{\partial x} = ? $ 

The first thing we need to recognize is that the $c^Tx$ is a scalar and x is a vector. So this is taking a derivative of a scaler with respect to a vector and it can be tricky sometimes(not in this case). The main idea is that we look at this thing element by element. So we are going to look at what is  $\frac{\partial c^T x}{\partial x_k} $  and generalize from there.

We write the statement in a familiar form:

$$\dfrac{\partial c^T x}{\partial x_k} =\dfrac{\partial \sum_{j} c_j x_j}{\partial x_k}=\sum_{j}c_j\dfrac{\partial x_j}{\partial x_k}= \sum_{j}c_j \delta_{jk} $$

Here in the last equality we used the delta to express that  when the indices of $x$'s are same we are going to get the coefficient on that term and when they are different we will get zero. [i.e. fancy version of: $\partial (ax_1+bx_2+cx_3)/\partial x_2 = b $ )

Finally if we sum over $j$:

$$\dfrac{\partial c^T x}{\partial x_k} = \sum_{j}c_j \delta_{jk} = c_k$$

To see this imagine what happens when we sum over $j$. For every value of $j$ that is not k we will get zero. For the value of $j$ that is $k$ we will get the correspoinding coefficient ($c_k$). 

So if for any arbitrary $k^{th}$ element the result is $c_k$ then we can conclude :

$\dfrac{\partial c^T x}{\partial x} = c$  

Notice that the coefficient on x is transposed.

---

**Example 2** 

A slightly more involved example is as fallows:

$$\dfrac{\partial x^TB x}{\partial x} = ? $$

Following the similar steps:

$$\dfrac{\partial x^TB x}{\partial x_k} =\sum_{i}\sum_{j} b_{ij}\dfrac{\partial x_ix_j}{\partial x_k} $$

$$ = \sum_{i}\sum_{j} b_{ij}(x_j\delta_{ik} + x_i\delta_{jk})$$

$$ = \sum_{i}\sum_{j}b_{ij}x_j\delta_{ik} + \sum_{i}\sum_{j}b_{ij}x_i\delta_{jk}$$

Summing over i and j (We are summing over $i$ and $j$ because we want to get rid of $\delta_{ik}$  and $\delta_{jk}$and we do not have k as an index here):

$$=\sum_{j}b_{kj}x_j + \sum_{i}b_{ik}x_i$$

If you notice (using the summation-over-indices expressions I provide above) , that this is equivaltent to:

$$= (Bx)_k + (B^Tx)_k = [(B+B^T)x]_k$$

So we can generalize this as :

$$\dfrac{\partial x^TB x}{\partial x} = (B+B^T)x $$ 

---

**Example 3**

In this final example I want to prove $tr(AB)=tr(BA)$ using the Delta Trick. 

*Proof*.

We can denote the trace of any matrix $A$, using the $\delta$ as:

$$tr(A) = \sum_{i}\sum_{j}A_{ij}\delta_{ij}$$

So for $AB$:

$$tr(AB) = \sum_{i}\sum_{j}(AB)_{ij}\delta_{ij} = \sum_{i}\sum_{j}\sum_{k}a_{ik}b_{kj}\delta_{ij}$$

Sum over $j$:

$$= \sum_{i}\sum_{k}a_{ik}b_{ki}$$

Rearranging,

=$$\sum_{k}\sum_{i}b_{ki}a_{ik} $$

Introducing another index:

$$=\sum_{k}\sum_{j}\sum_{i} b_{ki}a_{ij}\delta_{jk}$$

Looking at the summation over $i$:

$$= \sum_{k}\sum_{j}(BA)_{kj}\delta_{jk}$$

By definition of the trace:

$$=tr(BA)$$

---

Hopefully this post introduces you the Delta Trick and shows the usefullnes of it.  
